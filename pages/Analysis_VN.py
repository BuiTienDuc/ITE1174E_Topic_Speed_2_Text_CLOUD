import streamlit as st
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import tempfile
import whisper
import soundfile as sf

# ==========================
# ğŸ¯ TRANG ANALYSIS
# ==========================
def show():

    st.markdown(
        "<h3 style='color:#2b6f3e;'>Analysis â€“ PhÃ¢n tÃ­ch Audio & Speech to Text</h3>",
        unsafe_allow_html=True
    )

    st.write(
        """
        Trang nÃ y cho phÃ©p ngÆ°á»i dÃ¹ng táº£i lÃªn file audio tiáº¿ng Viá»‡t,
        phÃ¢n tÃ­ch tÃ­n hiá»‡u Ã¢m thanh vÃ  thá»±c hiá»‡n chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n
        báº±ng mÃ´ hÃ¬nh Speech-to-Text mÃ£ nguá»“n má»Ÿ.
        """
    )

    st.write("---")

    # ==========================
    # ğŸµ UPLOAD AUDIO
    # ==========================
    audio_file = st.file_uploader(
        "ğŸ“¤ Upload Vietnamese audio file (WAV / MP3 / FLAC)",
        type=["wav", "mp3", "flac"]
    )

    if audio_file is None:
        st.info("Vui lÃ²ng upload file audio Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¢n tÃ­ch.")
        return

    # LÆ°u file táº¡m
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(audio_file.read())
        audio_path = tmp.name

    # ==========================
    # ğŸ“Š THÃ”NG TIN AUDIO
    # ==========================
    y, sr = librosa.load(audio_path, sr=None)

    duration = librosa.get_duration(y=y, sr=sr)

    st.subheader("ğŸ” ThÃ´ng tin Audio")
    col1, col2, col3 = st.columns(3)
    col1.metric("Sample Rate (Hz)", sr)
    col2.metric("Duration (seconds)", f"{duration:.2f}")
    col3.metric("Channels", "Mono")

    st.write("---")

    # ==========================
    # ğŸ“ˆ WAVEFORM
    # ==========================
    st.subheader("ğŸ“ˆ Waveform")

    fig, ax = plt.subplots(figsize=(10, 3))
    librosa.display.waveshow(y, sr=sr, ax=ax)
    ax.set_xlabel("Time (seconds)")
    ax.set_ylabel("Amplitude")
    st.pyplot(fig)

    # ==========================
    # ğŸ“Š SPECTROGRAM
    # ==========================
    st.subheader("ğŸ“Š Spectrogram")

    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)

    fig, ax = plt.subplots(figsize=(10, 4))
    img = librosa.display.specshow(
        D,
        sr=sr,
        x_axis="time",
        y_axis="hz",
        ax=ax
    )
    fig.colorbar(img, ax=ax, format="%+2.0f dB")
    st.pyplot(fig)

    st.write("---")

    # ==========================
    # ğŸ§  SPEECH TO TEXT
    # ==========================
    st.subheader("ğŸ§  Vietnamese Speech to Text")

    st.write(
        """
        Há»‡ thá»‘ng sá»­ dá»¥ng mÃ´ hÃ¬nh **Whisper (open-source)** Ä‘á»ƒ chuyá»ƒn Ä‘á»•i
        giá»ng nÃ³i tiáº¿ng Viá»‡t thÃ nh vÄƒn báº£n.
        """
    )

    if st.button("â–¶ï¸ Thá»±c hiá»‡n Speech-to-Text"):
        with st.spinner("Äang nháº­n dáº¡ng giá»ng nÃ³i..."):
            model = whisper.load_model("base")
            result = model.transcribe(audio_path, language="vi")

        transcript = result["text"]

        st.success("HoÃ n thÃ nh nháº­n dáº¡ng!")

        # ==========================
        # ğŸ“ Káº¾T QUáº¢ TRANSCRIPT
        # ==========================
        st.subheader("ğŸ“ Transcript (cÃ³ thá»ƒ chá»‰nh sá»­a)")

        edited_text = st.text_area(
            "Ná»™i dung chuyá»ƒn giá»ng nÃ³i â†’ vÄƒn báº£n:",
            transcript,
            height=300
        )

        # ==========================
        # ğŸ“¤ EXPORT
        # ==========================
        st.write("---")
        st.subheader("ğŸ“¤ Xuáº¥t Transcript")

        st.download_button(
            label="â¬‡ï¸ Táº£i file TXT",
            data=edited_text,
            file_name="meeting_transcript.txt",
            mime="text/plain"
        )

        # Thá»‘ng kÃª Ä‘Æ¡n giáº£n
        word_count = len(edited_text.split())
        st.info(f"ğŸ“Š Sá»‘ tá»« trong transcript: **{word_count}**")
